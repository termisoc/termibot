#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys, re, urllib.request, urllib.parse, urllib.error

from html.parser import HTMLParser

import postgresql.driver.dbapi20 as postgresql
conn = postgresql.connect(database=sys.argv[1], user='termibot', password='PASSWORD', host='127.0.0.1')
cur = conn.cursor()


class MyUrlOpener(urllib.request.FancyURLopener):
    version = "Mozilla/4.0"
urllib.request._urlopener=MyUrlOpener()


class TitleParser(HTMLParser):
    title = None
    url = None
    _in_title = False
    _in_p_class = False

    def handle_starttag(self, tag, attrs):
        if tag == 'title':
            self._in_title = True
        elif tag == 'p':
            for attr in attrs:
                if attr[0] == 'class' and attr[1] == 'success':
                    self._in_p_class = True
                    break
        elif self._in_p_class and tag == 'a':
            for attr in attrs:
                if attr[0] == 'href':
                    self.url = attr[1]
                    break
    def handle_endtag(self, tag):
        if tag == 'title':
            self._in_title = False
        elif tag == 'p':
            self._in_p_class = False
    def handle_data(self, data):
        if self._in_title:
            self.title = data


def parse(line):
    uri_prefix = r'((http://|https://|ftp://)[\w\-\@;\/?:&=%\$_.+!*\x27(),~#]+[\w\-\@;\/?&=%\$_+!*\x27()~])'
    uri_re = re.compile(uri_prefix)
    return uri_re.findall(line)

def shorten(url):
    try:
        data = urllib.request.urlopen("http://ur1.ca/",data=urllib.parse.urlencode({'longurl':url})).read()
    except:
        return ""

    parser = TitleParser()
    parser.feed(data.decode("utf-8"))
    return parser.url.strip()

def gettitle(url):
    try:
        data = urllib.request.urlopen(url)
    except:
        return "unknown"

    ctype = data.info()["Content-Type"]
    if ";" in ctype:
        (ctype, charset) = data.info()["Content-Type"].split(";")
        charset = charset.split("=")[1].lower()
    else:
        charset = 'utf-8'

    if ctype in ["text/html", "application/xhtml+xml"]:
        parser = TitleParser()
        parser.feed(data.read().decode(charset))
        title = parser.title
        if title != None:
            return re.sub(r"[\n\s]+"," ", title.strip())
        else:
            return "(%s)" % ctype
    else:
        return "(%s)" % ctype

def lookup(url, nick):
    # if url in database return database[url].{short,timestamp}
    cur.execute('SELECT * FROM urls WHERE LOWER(url) = LOWER(%s)', (url,))
    res = cur.fetchone()
    if res:
        timestamp = res[1].strftime("%b %d, %Y at %H:%M")
        return "[ %s — %s ] (first posted by %s at %s)" % (res[2], gettitle(url), res[3][0]+"\x0f"+res[3][1:], timestamp)
    else:
        # else shorten, store with timestamp
        short = shorten(url)
        cur.execute('INSERT INTO urls VALUES(%s, NOW(), %s, %s)', (url, short, nick))
        conn.commit()
        return "[ %s — %s ]" % (short, gettitle(url))

if __name__ == '__main__':
    nick, user, host, sender, channel = sys.stdin.readline().split()[0:5]
    line = sys.stdin.readline().strip()
    urls = [url[0] for url in parse(line)]
    for url in urls:
        print(channel + " " + lookup(url, nick))
